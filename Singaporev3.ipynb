{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import momepy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "\n",
    "import osmnx as ox\n",
    "\n",
    "import scripts.consolidate as consolidate\n",
    "import scripts.snap as snap\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pygeos\n",
    "\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import mapclassify\n",
    "import copy\n",
    "from libpysal.weights import Queen, KNN, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_crs = 3414\n",
    "\n",
    "place = \"Singapore\"\n",
    "\n",
    "latlng = (1.29, 103.85)\n",
    "dist = 30000\n",
    "\n",
    "study_area = gpd.read_file(\"./Singapore_studyArea.shp\").to_crs(epsg=4326)\n",
    "\n",
    "# assuming your geodataframe is called `gdf` and the geometry column is called `geometry`\n",
    "study_area = study_area.geometry.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_graph= ox.graph.graph_from_polygon(study_area, network_type='drive')\n",
    "osm_graph = ox.projection.project_graph(osm_graph, to_crs=local_crs)\n",
    "\n",
    "streets = ox.consolidate_intersections(osm_graph, rebuild_graph=True, tolerance=15, dead_ends=False)\n",
    "\n",
    "streets = ox.graph_to_gdfs(\n",
    "    osm_graph,\n",
    "    nodes=False,\n",
    "    edges=True,\n",
    "    node_geometry=False,\n",
    "    fill_edge_geometry=True\n",
    ")\n",
    "streets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_graph= ox.graph.graph_from_polygon(study_area, custom_filter='[\"railway\"~\"rail|subway|narrow_gauge|monorail\"]')\n",
    "osm_graph = ox.projection.project_graph(osm_graph, to_crs=local_crs)\n",
    "\n",
    "osm_graph = ox.consolidate_intersections(osm_graph, rebuild_graph=True, tolerance=15, dead_ends=False)\n",
    "\n",
    "rails = ox.graph_to_gdfs(\n",
    "    osm_graph,\n",
    "    nodes=False,\n",
    "    edges=True,\n",
    "    node_geometry=False,\n",
    "    fill_edge_geometry=True\n",
    ")\n",
    "rails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waters = []\n",
    "\n",
    "# Get the water bodies as geometries\n",
    "water_bodies = ox.geometries_from_polygon(study_area, tags={'natural': 'water'}).set_crs(\"epsg: 4326\").to_crs(local_crs)\n",
    "\n",
    "# Explode the GeoDataFrame into a GeoSeries of polygons and multipolygons\n",
    "gs = water_bodies.explode()\n",
    "\n",
    "# Convert each polygon into a MultiLineString\n",
    "mls = gs.geometry.boundary\n",
    "\n",
    "# Convert the MultiLineString into a DataFrame\n",
    "water_bodies = gpd.GeoDataFrame({'geometry': mls})\n",
    "\n",
    "# Add a column to specify the polygon ID\n",
    "water_bodies['polygon_id'] = gs.index\n",
    "\n",
    "print(water_bodies)\n",
    "\n",
    "for water_body in water_bodies.geometry:\n",
    "    # Create a LineString object from the coordinates\n",
    "    waters.append(water_body)\n",
    "\n",
    "coastlines = ox.geometries_from_polygon(study_area, tags={'natural': 'coastline'}).set_crs(\"epsg: 4326\").to_crs(local_crs)\n",
    "\n",
    "coastlines = coastlines[coastlines.geom_type == \"LineString\"].reset_index(drop=True)\n",
    "\n",
    "for coastline in coastlines.geometry:\n",
    "    # Create a LineString object from the coordinates\n",
    "    waters.append(coastline)\n",
    "\n",
    "# # Create a GeoDataFrame of the water area boundaries\n",
    "waters = gpd.GeoDataFrame(geometry=waters)\n",
    "waters = waters[[\"geometry\"]]\n",
    "waters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = streets.plot(figsize=(16, 16))\n",
    "rails.plot(ax=ax, color='r')\n",
    "waters.plot(ax=ax, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "barriers = pd.concat([streets.geometry, waters.geometry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unioned = barriers.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "polygons = shapely.ops.polygonize(unioned)\n",
    "enclosures = gpd.array.from_shapely(list(polygons), crs=local_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "railway_topo = consolidate.topology(rails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "closed = snap.close_gaps(railway_topo, tolerance=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "closed_topo = consolidate.topology(gpd.GeoDataFrame(geometry=closed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "extended_topo = snap.line_to_line(closed_topo, streets, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "additional = pd.concat([waters.geometry, extended_topo.geometry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sindex = gpd.GeoSeries(enclosures).sindex\n",
    "inp, res = sindex.query_bulk(additional.geometry, predicate='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unique = np.unique(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new = []\n",
    "\n",
    "for i in tqdm(unique, total=len(unique)):\n",
    "    poly = enclosures.data[i]  # get enclosure polygon\n",
    "    crossing = inp[res==i]  # get relevant additional barriers\n",
    "    buf = pygeos.buffer(poly, 0.01)  # to avoid floating point errors\n",
    "    crossing_ins = pygeos.intersection(buf, additional.values.data[crossing])  # keeping only parts of additional barriers within polygon\n",
    "    union = pygeos.union_all(np.append(crossing_ins, pygeos.boundary(poly)))  # union\n",
    "    polygons = np.array(list(shapely.ops.polygonize(_pygeos_to_shapely(union))))  # shapely.ops.polygonize\n",
    "    within = pygeos.covered_by(pygeos.from_shapely(polygons), buf)  # keep only those within original polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final_enclosures = gpd.GeoSeries(enclosures).drop(unique).append(gpd.GeoSeries(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_enclosures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gpd.GeoDataFrame(geometry=final_enclosures, crs=local_crs).to_parquet('./out/singapore/enclosures.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = gpd.read_file(\"./Singapore/Singapore_constituencies.shp\").to_crs(local_crs)\n",
    "auth[\"index\"] = range(len(auth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = ox.geometries.geometries_from_polygon(study_area, tags={'building':True})\n",
    "buildings = buildings[buildings.geom_type == \"Polygon\"].reset_index(drop=True)\n",
    "buildings = buildings[[\"geometry\"]].to_crs(local_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_buildings = gpd.sjoin(auth, buildings, op='intersects')\n",
    "count = auth_buildings.groupby('index').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = auth.merge(count.rename('counts'), left_on='index', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time w_queen = Queen.from_dataframe(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time w_k1 = KNN.from_dataframe(auth, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = copy.deepcopy(w_queen.neighbors)\n",
    "for i in w_queen.islands:\n",
    "    j = w_k1.neighbors[i][0]\n",
    "    neighbors[i] = [j]\n",
    "    neighbors[j].append(i)\n",
    "w = W(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
