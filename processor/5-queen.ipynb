{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import bokeh\n",
    "import geopandas as gpd\n",
    "import scipy\n",
    "import libpysal\n",
    "import momepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daskCluster = LocalCluster(threads_per_worker=2,\n",
    "                n_workers=8, memory_limit='100GB')\n",
    "\n",
    "client = Client(daskCluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_w(chunk_id):\n",
    "    # load cells of a chunk\n",
    "    cells = gpd.read_parquet(f\"./out/singapore/queen_{i}.pq\")\n",
    "\n",
    "    w = libpysal.weights.Queen.from_dataframe(cells, geom_col='tessellation')\n",
    "    w3 = momepy.sw_high(k=3, weights=w)\n",
    "    \n",
    "    scipy.sparse.save_npz(f\"../../urbangrammar_samba/spatial_signatures/weights/w_{chunk_id}.npz\", w.sparse)\n",
    "    scipy.sparse.save_npz(f\"../../urbangrammar_samba/spatial_signatures/weights/w3_{chunk_id}.npz\", w3.sparse)\n",
    "    \n",
    "    return f\"Chunk {chunk_id} processed sucessfully.\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
