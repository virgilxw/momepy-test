{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40629bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:23.871002Z",
     "iopub.status.busy": "2023-05-20T15:36:23.870435Z",
     "iopub.status.idle": "2023-05-20T15:36:25.528828Z",
     "shell.execute_reply": "2023-05-20T15:36:25.528123Z"
    },
    "papermill": {
     "duration": 1.664734,
     "end_time": "2023-05-20T15:36:25.530293",
     "exception": false,
     "start_time": "2023-05-20T15:36:23.865559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import momepy\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import unary_union\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import dask.dataframe\n",
    "import dask_geopandas\n",
    "import dask.distributed\n",
    "import deltalake\n",
    "import shapely.geometry\n",
    "import contextily\n",
    "import mercantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7951815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d601e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:25.541368Z",
     "iopub.status.busy": "2023-05-20T15:36:25.540738Z",
     "iopub.status.idle": "2023-05-20T15:36:25.545722Z",
     "shell.execute_reply": "2023-05-20T15:36:25.544798Z"
    },
    "papermill": {
     "duration": 0.012959,
     "end_time": "2023-05-20T15:36:25.547336",
     "exception": false,
     "start_time": "2023-05-20T15:36:25.534377",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set the local coordinate reference system to EPSG 3414 (which is the projected CRS used in singapore)\n",
    "local_crs = 3414\n",
    "\n",
    "# Define the place of interest as a string variable\n",
    "place = \"singapore\"\n",
    "\n",
    "# Define the latitude and longitude coordinates of the center point of the study area as a tuple\n",
    "latlng = (1.29, 103.85)\n",
    "\n",
    "# Define the distance in meters from the center point that the study area will cover\n",
    "dist = 30000\n",
    "\n",
    "# Read in the study area polygon shapefile, which is in the local CRS, and convert it to EPSG 4326 (WGS 84) for compatibility with other data sources\n",
    "study_area = f\"./source/{place}_studyArea.shp\"\n",
    "\n",
    "country = \"singapore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204308f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:25.569184Z",
     "iopub.status.busy": "2023-05-20T15:36:25.568666Z",
     "iopub.status.idle": "2023-05-20T15:36:25.747103Z",
     "shell.execute_reply": "2023-05-20T15:36:25.746281Z"
    },
    "papermill": {
     "duration": 0.185116,
     "end_time": "2023-05-20T15:36:25.749072",
     "exception": false,
     "start_time": "2023-05-20T15:36:25.563956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the study area polygon shapefile, which is in the local CRS, and convert it to EPSG 4326 (WGS 84) for compatibility with other data sources\n",
    "study_area = gpd.read_file(study_area).to_crs(epsg=4326)\n",
    "\n",
    "\n",
    "# Calculate the union of all study area polygons to create a single polygon that covers the entire study area\n",
    "study_area_polygon = study_area.geometry.unary_union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b4213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:25.759112Z",
     "iopub.status.busy": "2023-05-20T15:36:25.758359Z",
     "iopub.status.idle": "2023-05-20T15:37:17.590105Z",
     "shell.execute_reply": "2023-05-20T15:37:17.588899Z"
    },
    "papermill": {
     "duration": 51.840454,
     "end_time": "2023-05-20T15:37:17.593615",
     "exception": false,
     "start_time": "2023-05-20T15:36:25.753161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the study area polygon to extract water geometries (i.e. bodies of water) from OpenStreetMap data using the `geometries_from_polygon` function from the `osmnx` library\n",
    "# `tags` parameter specifies which OSM tags to include in the extraction (in this case, only include natural=water tags)\n",
    "water = ox.geometries.geometries_from_polygon(study_area_polygon, tags={\"natural\": \"water\"}).reset_index(drop=True)\n",
    "\n",
    "# Preview the first few rows of the resulting GeoDataFrame\n",
    "water.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f3ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:17.604287Z",
     "iopub.status.busy": "2023-05-20T15:37:17.603637Z",
     "iopub.status.idle": "2023-05-20T15:37:17.616407Z",
     "shell.execute_reply": "2023-05-20T15:37:17.615634Z"
    },
    "papermill": {
     "duration": 0.019888,
     "end_time": "2023-05-20T15:37:17.617980",
     "exception": false,
     "start_time": "2023-05-20T15:37:17.598092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'gdf' is your GeoDataFrame\n",
    "geometry_types = water.geometry.geom_type\n",
    "\n",
    "# Create a mask for polygons and multipolygons\n",
    "mask = (geometry_types == 'Polygon') | (geometry_types == 'MultiPolygon')\n",
    "\n",
    "# Filter the GeoDataFrame\n",
    "water = water[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c4983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:17.628027Z",
     "iopub.status.busy": "2023-05-20T15:37:17.627744Z",
     "iopub.status.idle": "2023-05-20T15:37:17.632500Z",
     "shell.execute_reply": "2023-05-20T15:37:17.631800Z"
    },
    "papermill": {
     "duration": 0.011308,
     "end_time": "2023-05-20T15:37:17.633765",
     "exception": false,
     "start_time": "2023-05-20T15:37:17.622457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'gdf' is your GeoDataFrame\n",
    "geometry_types = water.geometry.geom_type\n",
    "\n",
    "# Get unique types\n",
    "unique_geometry_types = geometry_types.unique()\n",
    "\n",
    "# Print types\n",
    "print(unique_geometry_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ce1e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:17.643484Z",
     "iopub.status.busy": "2023-05-20T15:37:17.643053Z",
     "iopub.status.idle": "2023-05-20T15:37:17.646634Z",
     "shell.execute_reply": "2023-05-20T15:37:17.645973Z"
    },
    "papermill": {
     "duration": 0.009832,
     "end_time": "2023-05-20T15:37:17.647810",
     "exception": false,
     "start_time": "2023-05-20T15:37:17.637978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drop all non-geometry columns\n",
    "def drop_columns(df):\n",
    "    df = df.drop(df.columns.difference(['geometry']), 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88645194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:17.657579Z",
     "iopub.status.busy": "2023-05-20T15:37:17.657184Z",
     "iopub.status.idle": "2023-05-20T15:37:18.095253Z",
     "shell.execute_reply": "2023-05-20T15:37:18.094012Z"
    },
    "papermill": {
     "duration": 0.445159,
     "end_time": "2023-05-20T15:37:18.096974",
     "exception": false,
     "start_time": "2023-05-20T15:37:17.651815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# of a geodataframe that only have polyogns, extract all outlines into a geodataframe of linestrings\n",
    "\n",
    "outlines = water.copy()\n",
    "outlines[\"geometry\"] = outlines.boundary.to_crs(local_crs)\n",
    "outlines = outlines.drop(outlines.columns.difference(['geometry']), 1)\n",
    "\n",
    "outlines.head()\n",
    "\n",
    "outlines.to_parquet(f\"./out/{place}/water_outlines.pq\")\n",
    "\n",
    "# outlines = outlines.loc[outlines.geometry.type == \"LineString\"]\n",
    "# outlines = outlines.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If study_area and water are lists of geometries\n",
    "study_area_geometry = unary_union(study_area.geometry)\n",
    "water_geometry = unary_union(water.geometry)\n",
    "\n",
    "# Perform the difference operation\n",
    "result = study_area_geometry.difference(water_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07379167",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_area_a = gpd.GeoDataFrame(geometry=[result])\n",
    "study_area_a.crs = study_area.crs\n",
    "\n",
    "study_area = study_area_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892937ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:18.108071Z",
     "iopub.status.busy": "2023-05-20T15:37:18.107575Z",
     "iopub.status.idle": "2023-05-20T16:26:08.507158Z",
     "shell.execute_reply": "2023-05-20T16:26:08.506030Z"
    },
    "papermill": {
     "duration": 2929.862951,
     "end_time": "2023-05-20T16:26:07.964812",
     "exception": false,
     "start_time": "2023-05-20T15:37:18.101861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Overlay the `water` GeoDataFrame on top of the `study_area` polygon using the 'difference' method to remove the water geometries from the study area polygon\n",
    "# study_area = study_area.overlay(water, how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c1675",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a plot of the `study_area` polygon using the `plot()` method\n",
    "study_area.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "collection = catalog.get_collection(\"ms-buildings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee099ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = collection.assets[\"delta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_options = {\n",
    "    \"account_name\": asset.extra_fields[\"table:storage_options\"][\"account_name\"],\n",
    "    \"sas_token\": asset.extra_fields[\"table:storage_options\"][\"credential\"],\n",
    "}\n",
    "table = deltalake.DeltaTable(asset.href, storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b43426",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f667c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadkeys = [\n",
    "    int(mercantile.quadkey(tile))\n",
    "    for tile in mercantile.tiles(*area_of_interest.bounds, zooms=9)\n",
    "]\n",
    "quadkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "uris = table.file_uris([(\"quadkey\", \"in\", quadkeys)])\n",
    "uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777069fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask_geopandas.read_parquet(uris, storage_options=storage_options)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c809e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df.clip(area_of_interest).compute()\n",
    "subset.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f421098",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0817732",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.explode(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings[buildings.geometry.geom_type == 'Polygon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8930d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of geometry types in the GeoDataFrame\n",
    "geometry_types = buildings.geometry.geom_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.to_crs(local_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"uID\"] = range(len(buildings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1134c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['geometry'] = buildings.geometry.buffer(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f0a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c71974cd",
   "metadata": {},
   "source": [
    "# UNCOMMENT THESE BLOCKS TO DOWNLOAD DATA FROM OSMNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81691040",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Use the study area polygon to extract building geometries from OpenStreetMap data using the `geometries_from_polygon` function from the `osmnx` library\n",
    "# # `tags` parameter specifies which OSM tags to include in the extraction (in this case, only include building tags)\n",
    "# buildings = ox.geometries.geometries_from_polygon(study_area_polygon, tags={'building':True})\n",
    "\n",
    "# # Preview the first few rows of the resulting GeoDataFrame\n",
    "# buildings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58c413",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Select only building geometries that are valid polygons (i.e. exclude other geometry types like Points and MultiPolygons) and convert the GeoDataFrame to the local coordinate reference system\n",
    "# buildings = buildings[buildings.geom_type == \"Polygon\"].reset_index(drop=True)\n",
    "# buildings = buildings[[\"geometry\"]].to_crs(local_crs)\n",
    "\n",
    "# # Print the count of each geometry type to check that only Polygon geometries remain\n",
    "# print(buildings.geom_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef606a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Merge adjacent or overlapping building polygons using the `unary_union()` method\n",
    "# merged = buildings.geometry.unary_union\n",
    "\n",
    "# # Convert the merged geometry back to a GeoDataFrame with a single polygon\n",
    "# merged_buildings_gdf = gpd.GeoDataFrame(geometry=[merged])\n",
    "\n",
    "# # Explode the GeoDataFrame to convert the single polygon back into multiple separate polygons\n",
    "# buildings = merged_buildings_gdf.explode()\n",
    "\n",
    "# # Select only building geometries that are valid polygons (i.e. exclude other geometry types like Points and MultiPolygons)\n",
    "# buildings = buildings[buildings.geom_type == \"Polygon\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060a8db",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Add a new column to the GeoDataFrame called \"uID\" containing a range of values from 0 to the length of the GeoDataFrame (minus 1)\n",
    "# buildings[\"uID\"] = range(len(buildings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d11b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print out the count of each type of geometry in the GeoDataFrame\n",
    "print(buildings.geom_type.value_counts())\n",
    "\n",
    "# Display the first few rows of the GeoDataFrame\n",
    "buildings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495f742",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "osm_graph= ox.graph.graph_from_polygon(study_area_polygon, network_type='drive')\n",
    "osm_graph = ox.projection.project_graph(osm_graph, to_crs=local_crs)\n",
    "streets = ox.graph_to_gdfs(\n",
    "    osm_graph,\n",
    "    nodes=False,\n",
    "    edges=True,\n",
    "    node_geometry=False,\n",
    "    fill_edge_geometry=True\n",
    ")\n",
    "\n",
    "streets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b3308",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create a new column in the streets GeoDataFrame called 'motorway' that is 1 if the 'highway' column contains 'motorway', 'trunk', 'motorway_link' or 'trunk_link' and 0 otherwise\n",
    "# def is_motorway(highway):\n",
    "#     if isinstance(highway, list):\n",
    "#         return 1 if any(x in ['motorway', 'trunk', 'motorway_link', 'trunk_link'] for x in highway) else 0\n",
    "#     else:\n",
    "#         return 1 if highway in ['motorway', 'trunk', 'motorway_link', 'trunk_link'] else 0\n",
    "# streets[\"is_motorway\"] = streets[\"highway\"].apply(is_motorway)\n",
    "\n",
    "# def is_primary(highway):\n",
    "#     if isinstance(highway, list):\n",
    "#         return 1 if any(x in ['primary', 'primary_link'] for x in highway) else 0\n",
    "#     else:\n",
    "#         return 1 if highway in ['primary', 'primary_link'] else 0\n",
    "    \n",
    "# def is_link(highway):\n",
    "#     if isinstance(highway, list):\n",
    "#         return 1 if any(x in ['motorway_link', 'trunk_link', \"primary_link\", \"secondary_link\", \"tertiary_link\"] for x in highway) else 0\n",
    "#     else:\n",
    "#         return 1 if highway in ['motorway_link', 'trunk_link', \"primary_link\", \"secondary_link\", \"tertiary_link\"] else 0\n",
    "    \n",
    "# def is_roundabout(junction, highway):\n",
    "    \n",
    "#     if isinstance(junction, list):\n",
    "#         if any(x in ['roundabout', 'circular'] for x in junction):\n",
    "#             return 1\n",
    "#     else:\n",
    "#         if junction in ['roundabout', 'circular']:\n",
    "#             return 1\n",
    "    \n",
    "#     if isinstance(highway, list):\n",
    "#         return 1 if any(x in ['mini_roundabout'] for x in highway) else 0\n",
    "#     else:\n",
    "#         return 1 if junction in ['roundabout'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c463ed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # get all the unique values of the 'highway' column of streets\n",
    "\n",
    "# highway_types = set()\n",
    "# for highway in streets[\"highway\"]:\n",
    "#     if isinstance(highway, list):\n",
    "#         for h in highway:\n",
    "#             highway_types.add(h)\n",
    "#     else:\n",
    "#         print(highway)\n",
    "#         highway_types.add(highway)\n",
    "\n",
    "# # assign a key to each street type in highway_types\n",
    "# key = {types:key+1 for key, types in enumerate(highway_types)}\n",
    "# key[\"residential\"] = 0\n",
    "# key[\"living_street\"] = 0\n",
    "# key[\"unclassified\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ef70c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49cee50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# streets[\"highway_types\"] = streets[\"highway\"].apply(lambda x: key[x] if isinstance(x, str) else key[x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540acfc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# streets[\"is_motorway\"] = streets[\"highway\"].apply(is_motorway)\n",
    "# streets[\"is_primary\"] = streets[\"highway\"].apply(is_primary)\n",
    "# streets[\"is_link\"] = streets[\"highway\"].apply(is_link)\n",
    "# streets[\"is_roundabout\"] = streets.apply(lambda x: is_roundabout(x[\"junction\"], x[\"highway\"]), axis=1)\n",
    "# streets[\"all_ones\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572a40f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# streets[\"road_char_field\"] = streets.apply(lambda row: 0 if row[\"is_roundabout\"] == 1 else (2 if row[\"is_link\"] == 1 else 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1922d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "streets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6f1d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "buildings.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a799e4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_area = study_area.to_crs(local_crs)\n",
    "study_area.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b461d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create directory ./out/{place} if it does not exist\n",
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        \n",
    "create_dir(f\"./out/{place}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e095932",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## convert streets_noded_gdf, buildings, and study_area to local_crs\n",
    "\n",
    "buildings.to_parquet(f\"./out/{place}/buildings_raw.pq\")\n",
    "\n",
    "study_area.to_parquet(f\"./out/{place}/study_area.pq\")\n",
    "\n",
    "# streets.to_parquet(\"./out/{place}/streets.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba32792",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "water[['geometry']].to_crs(local_crs).to_parquet(f\"./out/{place}/water.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4b851",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate through the columns of streets, if it is a list, cast it as a string\n",
    "\n",
    "for col in streets.columns:\n",
    "    for i, row in streets.iterrows():\n",
    "        if isinstance(row[col], list):\n",
    "            streets.loc[i, col] = ','.join(str(streets.loc[i, col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b87707",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# define the directory path\n",
    "directory_path = f\"./out/{place}/\"\n",
    "\n",
    "# define the pattern to match the files you want to delete\n",
    "pattern = directory_path + \"streets_raw*\"\n",
    "\n",
    "# use glob to get a list of files that match the pattern\n",
    "file_list = glob.glob(pattern)\n",
    "\n",
    "# loop through the list of files and delete each file\n",
    "for file_path in file_list:\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"{file_path} has been deleted.\")\n",
    "    except OSError:\n",
    "        print(f\"Error while deleting file: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b43fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save streets to shapefile\n",
    "streets.to_file(f\"./out/{place}/streets_raw.shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d387e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a polygon geodataframe from creating a 2 meter buffer around every line in streets_noded_gdf and dissolve it into study_area\n",
    "\n",
    "# streets_noded_gdf_buffer = dgpd.from_geopandas(streets_noded_gdf, npartitions=4)\n",
    "# streets_noded_gdf_buffer.buffer(2)\n",
    "\n",
    "# study_area_dgpd = dgpd.from_geopandas(study_area, npartitions=4).append(streets_noded_gdf_buffer).dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98f8c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = study_area_dgpd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ae1a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # dissolve streets_noded_gdf_buffer into study_area into one multipolygon in a geodataframe\n",
    "# concat = pd.concat([study_area, streets_noded_gdf_buffer])\n",
    "\n",
    "# study_area_polygon = gdf.geometry.unary_union\n",
    "# study_area = gpd.GeoDataFrame(geometry=[dissolved_geom], crs=gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ca8da",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enclosures = momepy.enclosures(noded_gdf , limit= study_area.to_crs(local_crs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ad5ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enclosures.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296bff1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Perform a spatial join of the overlapping polygons with themselves\n",
    "# spatial_join = gpd.sjoin(enclosures, enclosures, how=\"inner\", op=\"intersects\")\n",
    "\n",
    "# # Count the number of overlapping polygons for each polygon\n",
    "# overlapping_counts = spatial_join.groupby([\"eID_left\"]).size()\n",
    "\n",
    "# # Get the polygons that overlap with more than one other polygon\n",
    "# overlapping_count = overlapping_counts[overlapping_counts > 30].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b99300",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2986.130995,
   "end_time": "2023-05-20T16:26:09.289984",
   "environment_variables": {},
   "exception": null,
   "input_path": "1.0-osmnx.ipynb",
   "output_path": "./out/atlanta/1.0-osmnx-output.ipynb",
   "parameters": {
    "dist": 30000,
    "latlng": [
     33.748783,
     -84.388168
    ],
    "local_crs": 26917,
    "place": "atlanta",
    "study_area": "./source/atlanta_studyArea.shp"
   },
   "start_time": "2023-05-20T15:36:23.158989",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d4a16af7eecff68ca78f81aec8d4e5ee20d890b8903eddd3dd732009f4fdc6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
