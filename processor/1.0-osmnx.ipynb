{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40629bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:23.871002Z",
     "iopub.status.busy": "2023-05-20T15:36:23.870435Z",
     "iopub.status.idle": "2023-05-20T15:36:25.528828Z",
     "shell.execute_reply": "2023-05-20T15:36:25.528123Z"
    },
    "papermill": {
     "duration": 1.664734,
     "end_time": "2023-05-20T15:36:25.530293",
     "exception": false,
     "start_time": "2023-05-20T15:36:23.865559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/virgilxw/miniconda3/lib/python3.10/site-packages/osmnx/projection.py:3: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import momepy\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import unary_union\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d601e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:25.541368Z",
     "iopub.status.busy": "2023-05-20T15:36:25.540738Z",
     "iopub.status.idle": "2023-05-20T15:36:25.545722Z",
     "shell.execute_reply": "2023-05-20T15:36:25.544798Z"
    },
    "papermill": {
     "duration": 0.012959,
     "end_time": "2023-05-20T15:36:25.547336",
     "exception": false,
     "start_time": "2023-05-20T15:36:25.534377",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set the local coordinate reference system to EPSG 3414 (which is the projected CRS used in singapore)\n",
    "local_crs = 3414\n",
    "\n",
    "# Define the place of interest as a string variable\n",
    "place = \"singapore\"\n",
    "\n",
    "# Define the latitude and longitude coordinates of the center point of the study area as a tuple\n",
    "latlng = (1.29, 103.85)\n",
    "\n",
    "# Define the distance in meters from the center point that the study area will cover\n",
    "dist = 30000\n",
    "\n",
    "# Read in the study area polygon shapefile, which is in the local CRS, and convert it to EPSG 4326 (WGS 84) for compatibility with other data sources\n",
    "study_area = f\"./source/{place}_studyArea.shp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f35f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:25.556055Z",
     "iopub.status.busy": "2023-05-20T15:36:25.555658Z",
     "iopub.status.idle": "2023-05-20T15:36:25.559265Z",
     "shell.execute_reply": "2023-05-20T15:36:25.558601Z"
    },
    "papermill": {
     "duration": 0.009062,
     "end_time": "2023-05-20T15:36:25.560431",
     "exception": false,
     "start_time": "2023-05-20T15:36:25.551369",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "local_crs = 26917\n",
    "place = \"atlanta\"\n",
    "latlng = \"(33.748783, -84.388168)\"\n",
    "dist = 30000\n",
    "study_area = \"./source/atlanta_studyArea.shp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "204308f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:25.569184Z",
     "iopub.status.busy": "2023-05-20T15:36:25.568666Z",
     "iopub.status.idle": "2023-05-20T15:36:25.747103Z",
     "shell.execute_reply": "2023-05-20T15:36:25.746281Z"
    },
    "papermill": {
     "duration": 0.185116,
     "end_time": "2023-05-20T15:36:25.749072",
     "exception": false,
     "start_time": "2023-05-20T15:36:25.563956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the study area polygon shapefile, which is in the local CRS, and convert it to EPSG 4326 (WGS 84) for compatibility with other data sources\n",
    "study_area = gpd.read_file(study_area).to_crs(epsg=4326)\n",
    "\n",
    "\n",
    "# Calculate the union of all study area polygons to create a single polygon that covers the entire study area\n",
    "study_area_polygon = study_area.geometry.unary_union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1b4213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:36:25.759112Z",
     "iopub.status.busy": "2023-05-20T15:36:25.758359Z",
     "iopub.status.idle": "2023-05-20T15:37:17.590105Z",
     "shell.execute_reply": "2023-05-20T15:37:17.588899Z"
    },
    "papermill": {
     "duration": 51.840454,
     "end_time": "2023-05-20T15:37:17.593615",
     "exception": false,
     "start_time": "2023-05-20T15:36:25.753161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>ele</th>\n",
       "      <th>gnis:county_id</th>\n",
       "      <th>gnis:created</th>\n",
       "      <th>gnis:feature_id</th>\n",
       "      <th>gnis:state_id</th>\n",
       "      <th>name</th>\n",
       "      <th>natural</th>\n",
       "      <th>water</th>\n",
       "      <th>waterway</th>\n",
       "      <th>...</th>\n",
       "      <th>ship</th>\n",
       "      <th>fixme</th>\n",
       "      <th>addr:housenumber</th>\n",
       "      <th>addr:state</th>\n",
       "      <th>addr:street</th>\n",
       "      <th>source:name</th>\n",
       "      <th>boundary</th>\n",
       "      <th>attraction</th>\n",
       "      <th>operator</th>\n",
       "      <th>is_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((-84.38361 33.44442, -84.38371 33.444...</td>\n",
       "      <td>235.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>water</td>\n",
       "      <td>river</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((-84.38361 33.44442, -84.38371 33.444...</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>water</td>\n",
       "      <td>river</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((-84.46936 33.45498, -84.46950 33.455...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pye Lake</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((-84.27556 33.21548, -84.27549 33.215...</td>\n",
       "      <td>267.00000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((-84.39327 33.36455, -84.39328 33.364...</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>water</td>\n",
       "      <td>river</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry              ele  \\\n",
       "0  POLYGON ((-84.38361 33.44442, -84.38371 33.444...            235.0   \n",
       "1  POLYGON ((-84.38361 33.44442, -84.38371 33.444...            231.0   \n",
       "2  POLYGON ((-84.46936 33.45498, -84.46950 33.455...              NaN   \n",
       "3  POLYGON ((-84.27556 33.21548, -84.27549 33.215...  267.00000000000   \n",
       "4  POLYGON ((-84.39327 33.36455, -84.39328 33.364...            230.0   \n",
       "\n",
       "  gnis:county_id gnis:created gnis:feature_id gnis:state_id      name natural  \\\n",
       "0            NaN          NaN             NaN           NaN       NaN   water   \n",
       "1            NaN          NaN             NaN           NaN       NaN   water   \n",
       "2            NaN          NaN          337950           NaN  Pye Lake   water   \n",
       "3            NaN          NaN             NaN           NaN       NaN   water   \n",
       "4            NaN          NaN             NaN           NaN       NaN   water   \n",
       "\n",
       "   water waterway  ... ship fixme addr:housenumber addr:state addr:street  \\\n",
       "0  river      NaN  ...  NaN   NaN              NaN        NaN         NaN   \n",
       "1  river      NaN  ...  NaN   NaN              NaN        NaN         NaN   \n",
       "2    NaN      NaN  ...  NaN   NaN              NaN        NaN         NaN   \n",
       "3    NaN      NaN  ...  NaN   NaN              NaN        NaN         NaN   \n",
       "4  river      NaN  ...  NaN   NaN              NaN        NaN         NaN   \n",
       "\n",
       "  source:name boundary attraction operator is_in  \n",
       "0         NaN      NaN        NaN      NaN   NaN  \n",
       "1         NaN      NaN        NaN      NaN   NaN  \n",
       "2         NaN      NaN        NaN      NaN   NaN  \n",
       "3         NaN      NaN        NaN      NaN   NaN  \n",
       "4         NaN      NaN        NaN      NaN   NaN  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the study area polygon to extract water geometries (i.e. bodies of water) from OpenStreetMap data using the `geometries_from_polygon` function from the `osmnx` library\n",
    "# `tags` parameter specifies which OSM tags to include in the extraction (in this case, only include natural=water tags)\n",
    "water = ox.geometries.geometries_from_polygon(study_area_polygon, tags={\"natural\": \"water\"}).reset_index(drop=True)\n",
    "\n",
    "# Preview the first few rows of the resulting GeoDataFrame\n",
    "water.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350f3ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:17.604287Z",
     "iopub.status.busy": "2023-05-20T15:37:17.603637Z",
     "iopub.status.idle": "2023-05-20T15:37:17.616407Z",
     "shell.execute_reply": "2023-05-20T15:37:17.615634Z"
    },
    "papermill": {
     "duration": 0.019888,
     "end_time": "2023-05-20T15:37:17.617980",
     "exception": false,
     "start_time": "2023-05-20T15:37:17.598092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'gdf' is your GeoDataFrame\n",
    "geometry_types = water.geometry.geom_type\n",
    "\n",
    "# Create a mask for polygons and multipolygons\n",
    "mask = (geometry_types == 'Polygon') | (geometry_types == 'MultiPolygon')\n",
    "\n",
    "# Filter the GeoDataFrame\n",
    "water = water[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "412c4983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:17.628027Z",
     "iopub.status.busy": "2023-05-20T15:37:17.627744Z",
     "iopub.status.idle": "2023-05-20T15:37:17.632500Z",
     "shell.execute_reply": "2023-05-20T15:37:17.631800Z"
    },
    "papermill": {
     "duration": 0.011308,
     "end_time": "2023-05-20T15:37:17.633765",
     "exception": false,
     "start_time": "2023-05-20T15:37:17.622457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Polygon' 'MultiPolygon']\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'gdf' is your GeoDataFrame\n",
    "geometry_types = water.geometry.geom_type\n",
    "\n",
    "# Get unique types\n",
    "unique_geometry_types = geometry_types.unique()\n",
    "\n",
    "# Print types\n",
    "print(unique_geometry_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c5ce1e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:17.643484Z",
     "iopub.status.busy": "2023-05-20T15:37:17.643053Z",
     "iopub.status.idle": "2023-05-20T15:37:17.646634Z",
     "shell.execute_reply": "2023-05-20T15:37:17.645973Z"
    },
    "papermill": {
     "duration": 0.009832,
     "end_time": "2023-05-20T15:37:17.647810",
     "exception": false,
     "start_time": "2023-05-20T15:37:17.637978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drop all non-geometry columns\n",
    "def drop_columns(df):\n",
    "    df = df.drop(df.columns.difference(['geometry']), 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88645194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:17.657579Z",
     "iopub.status.busy": "2023-05-20T15:37:17.657184Z",
     "iopub.status.idle": "2023-05-20T15:37:18.095253Z",
     "shell.execute_reply": "2023-05-20T15:37:18.094012Z"
    },
    "papermill": {
     "duration": 0.445159,
     "end_time": "2023-05-20T15:37:18.096974",
     "exception": false,
     "start_time": "2023-05-20T15:37:17.651815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24600/2010371134.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  outlines = outlines.drop(outlines.columns.difference(['geometry']), 1)\n"
     ]
    }
   ],
   "source": [
    "# of a geodataframe that only have polyogns, extract all outlines into a geodataframe of linestrings\n",
    "\n",
    "outlines = water.copy()\n",
    "outlines[\"geometry\"] = outlines.boundary.to_crs(local_crs)\n",
    "outlines = outlines.drop(outlines.columns.difference(['geometry']), 1)\n",
    "\n",
    "outlines.head()\n",
    "\n",
    "outlines.to_parquet(f\"./out/{place}/water_outlines.pq\")\n",
    "\n",
    "# outlines = outlines.loc[outlines.geometry.type == \"LineString\"]\n",
    "# outlines = outlines.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7425d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If study_area and water are lists of geometries\n",
    "study_area_geometry = unary_union(study_area.geometry)\n",
    "water_geometry = unary_union(water.geometry)\n",
    "\n",
    "# Perform the difference operation\n",
    "result = study_area_geometry.difference(water_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07379167",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_area_a = gpd.GeoDataFrame(geometry=[result])\n",
    "study_area_a.crs = study_area.crs\n",
    "\n",
    "study_area = study_area_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892937ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T15:37:18.108071Z",
     "iopub.status.busy": "2023-05-20T15:37:18.107575Z",
     "iopub.status.idle": "2023-05-20T16:26:08.507158Z",
     "shell.execute_reply": "2023-05-20T16:26:08.506030Z"
    },
    "papermill": {
     "duration": 2929.862951,
     "end_time": "2023-05-20T16:26:07.964812",
     "exception": false,
     "start_time": "2023-05-20T15:37:18.101861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Overlay the `water` GeoDataFrame on top of the `study_area` polygon using the 'difference' method to remove the water geometries from the study area polygon\n",
    "# study_area = study_area.overlay(water, how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c1675",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a plot of the `study_area` polygon using the `plot()` method\n",
    "study_area.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81691040",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the study area polygon to extract building geometries from OpenStreetMap data using the `geometries_from_polygon` function from the `osmnx` library\n",
    "# `tags` parameter specifies which OSM tags to include in the extraction (in this case, only include building tags)\n",
    "buildings = ox.geometries.geometries_from_polygon(study_area_polygon, tags={'building':True})\n",
    "\n",
    "# Preview the first few rows of the resulting GeoDataFrame\n",
    "buildings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58c413",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only building geometries that are valid polygons (i.e. exclude other geometry types like Points and MultiPolygons) and convert the GeoDataFrame to the local coordinate reference system\n",
    "buildings = buildings[buildings.geom_type == \"Polygon\"].reset_index(drop=True)\n",
    "buildings = buildings[[\"geometry\"]].to_crs(local_crs)\n",
    "\n",
    "# Print the count of each geometry type to check that only Polygon geometries remain\n",
    "print(buildings.geom_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef606a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge adjacent or overlapping building polygons using the `unary_union()` method\n",
    "merged = buildings.geometry.unary_union\n",
    "\n",
    "# Convert the merged geometry back to a GeoDataFrame with a single polygon\n",
    "merged_buildings_gdf = gpd.GeoDataFrame(geometry=[merged])\n",
    "\n",
    "# Explode the GeoDataFrame to convert the single polygon back into multiple separate polygons\n",
    "buildings = merged_buildings_gdf.explode()\n",
    "\n",
    "# Select only building geometries that are valid polygons (i.e. exclude other geometry types like Points and MultiPolygons)\n",
    "buildings = buildings[buildings.geom_type == \"Polygon\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060a8db",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a new column to the GeoDataFrame called \"uID\" containing a range of values from 0 to the length of the GeoDataFrame (minus 1)\n",
    "buildings[\"uID\"] = range(len(buildings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d11b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print out the count of each type of geometry in the GeoDataFrame\n",
    "print(buildings.geom_type.value_counts())\n",
    "\n",
    "# Display the first few rows of the GeoDataFrame\n",
    "buildings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495f742",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "osm_graph= ox.graph.graph_from_polygon(study_area_polygon, network_type='drive')\n",
    "osm_graph = ox.projection.project_graph(osm_graph, to_crs=local_crs)\n",
    "streets = ox.graph_to_gdfs(\n",
    "    osm_graph,\n",
    "    nodes=False,\n",
    "    edges=True,\n",
    "    node_geometry=False,\n",
    "    fill_edge_geometry=True\n",
    ")\n",
    "\n",
    "streets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b3308",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a new column in the streets GeoDataFrame called 'motorway' that is 1 if the 'highway' column contains 'motorway', 'trunk', 'motorway_link' or 'trunk_link' and 0 otherwise\n",
    "def is_motorway(highway):\n",
    "    if isinstance(highway, list):\n",
    "        return 1 if any(x in ['motorway', 'trunk', 'motorway_link', 'trunk_link'] for x in highway) else 0\n",
    "    else:\n",
    "        return 1 if highway in ['motorway', 'trunk', 'motorway_link', 'trunk_link'] else 0\n",
    "streets[\"is_motorway\"] = streets[\"highway\"].apply(is_motorway)\n",
    "\n",
    "def is_primary(highway):\n",
    "    if isinstance(highway, list):\n",
    "        return 1 if any(x in ['primary', 'primary_link'] for x in highway) else 0\n",
    "    else:\n",
    "        return 1 if highway in ['primary', 'primary_link'] else 0\n",
    "    \n",
    "def is_link(highway):\n",
    "    if isinstance(highway, list):\n",
    "        return 1 if any(x in ['motorway_link', 'trunk_link', \"primary_link\", \"secondary_link\", \"tertiary_link\"] for x in highway) else 0\n",
    "    else:\n",
    "        return 1 if highway in ['motorway_link', 'trunk_link', \"primary_link\", \"secondary_link\", \"tertiary_link\"] else 0\n",
    "    \n",
    "def is_roundabout(junction, highway):\n",
    "    \n",
    "    if isinstance(junction, list):\n",
    "        if any(x in ['roundabout', 'circular'] for x in junction):\n",
    "            return 1\n",
    "    else:\n",
    "        if junction in ['roundabout', 'circular']:\n",
    "            return 1\n",
    "    \n",
    "    if isinstance(highway, list):\n",
    "        return 1 if any(x in ['mini_roundabout'] for x in highway) else 0\n",
    "    else:\n",
    "        return 1 if junction in ['roundabout'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c463ed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get all the unique values of the 'highway' column of streets\n",
    "\n",
    "highway_types = set()\n",
    "for highway in streets[\"highway\"]:\n",
    "    if isinstance(highway, list):\n",
    "        for h in highway:\n",
    "            highway_types.add(h)\n",
    "    else:\n",
    "        print(highway)\n",
    "        highway_types.add(highway)\n",
    "\n",
    "# assign a key to each street type in highway_types\n",
    "key = {types:key+1 for key, types in enumerate(highway_types)}\n",
    "key[\"residential\"] = 0\n",
    "key[\"living_street\"] = 0\n",
    "key[\"unclassified\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ef70c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49cee50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "streets[\"highway_types\"] = streets[\"highway\"].apply(lambda x: key[x] if isinstance(x, str) else key[x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540acfc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "streets[\"is_motorway\"] = streets[\"highway\"].apply(is_motorway)\n",
    "streets[\"is_primary\"] = streets[\"highway\"].apply(is_primary)\n",
    "streets[\"is_link\"] = streets[\"highway\"].apply(is_link)\n",
    "streets[\"is_roundabout\"] = streets.apply(lambda x: is_roundabout(x[\"junction\"], x[\"highway\"]), axis=1)\n",
    "streets[\"all_ones\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572a40f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "streets[\"road_char_field\"] = streets.apply(lambda row: 0 if row[\"is_roundabout\"] == 1 else (2 if row[\"is_link\"] == 1 else 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1922d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "streets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6f1d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "buildings.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a799e4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_area = study_area.to_crs(local_crs)\n",
    "study_area.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b461d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create directory ./out/{place} if it does not exist\n",
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        \n",
    "create_dir(\"./out/{place}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e095932",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## convert streets_noded_gdf, buildings, and study_area to local_crs\n",
    "\n",
    "buildings.to_parquet(f\"./out/{place}/buildings_raw.pq\")\n",
    "\n",
    "study_area.to_parquet(f\"./out/{place}/study_area.pq\")\n",
    "\n",
    "# streets.to_parquet(\"./out/{place}/streets.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba32792",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "water.drop(columns=water.columns.difference(['geometry'])).to_crs(local_crs).reset_index(drop=True).to_parquet(f\"./out/{place}/water.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4b851",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate through the columns of streets, if it is a list, cast it as a string\n",
    "\n",
    "for col in streets.columns:\n",
    "    for i, row in streets.iterrows():\n",
    "        if isinstance(row[col], list):\n",
    "            streets.loc[i, col] = ','.join(str(streets.loc[i, col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b87707",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# define the directory path\n",
    "directory_path = f\"./out/{place}/\"\n",
    "\n",
    "# define the pattern to match the files you want to delete\n",
    "pattern = directory_path + \"streets_raw*\"\n",
    "\n",
    "# use glob to get a list of files that match the pattern\n",
    "file_list = glob.glob(pattern)\n",
    "\n",
    "# loop through the list of files and delete each file\n",
    "for file_path in file_list:\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"{file_path} has been deleted.\")\n",
    "    except OSError:\n",
    "        print(f\"Error while deleting file: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b43fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save streets to shapefile\n",
    "streets.to_file(f\"./out/{place}/streets_raw.shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d387e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a polygon geodataframe from creating a 2 meter buffer around every line in streets_noded_gdf and dissolve it into study_area\n",
    "\n",
    "# streets_noded_gdf_buffer = dgpd.from_geopandas(streets_noded_gdf, npartitions=4)\n",
    "# streets_noded_gdf_buffer.buffer(2)\n",
    "\n",
    "# study_area_dgpd = dgpd.from_geopandas(study_area, npartitions=4).append(streets_noded_gdf_buffer).dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98f8c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = study_area_dgpd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ae1a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # dissolve streets_noded_gdf_buffer into study_area into one multipolygon in a geodataframe\n",
    "# concat = pd.concat([study_area, streets_noded_gdf_buffer])\n",
    "\n",
    "# study_area_polygon = gdf.geometry.unary_union\n",
    "# study_area = gpd.GeoDataFrame(geometry=[dissolved_geom], crs=gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ca8da",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enclosures = momepy.enclosures(noded_gdf , limit= study_area.to_crs(local_crs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ad5ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enclosures.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296bff1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Perform a spatial join of the overlapping polygons with themselves\n",
    "# spatial_join = gpd.sjoin(enclosures, enclosures, how=\"inner\", op=\"intersects\")\n",
    "\n",
    "# # Count the number of overlapping polygons for each polygon\n",
    "# overlapping_counts = spatial_join.groupby([\"eID_left\"]).size()\n",
    "\n",
    "# # Get the polygons that overlap with more than one other polygon\n",
    "# overlapping_count = overlapping_counts[overlapping_counts > 30].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b99300",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2986.130995,
   "end_time": "2023-05-20T16:26:09.289984",
   "environment_variables": {},
   "exception": null,
   "input_path": "1.0-osmnx.ipynb",
   "output_path": "./out/atlanta/1.0-osmnx-output.ipynb",
   "parameters": {
    "dist": 30000,
    "latlng": [
     33.748783,
     -84.388168
    ],
    "local_crs": 26917,
    "place": "atlanta",
    "study_area": "./source/atlanta_studyArea.shp"
   },
   "start_time": "2023-05-20T15:36:23.158989",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d4a16af7eecff68ca78f81aec8d4e5ee20d890b8903eddd3dd732009f4fdc6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
