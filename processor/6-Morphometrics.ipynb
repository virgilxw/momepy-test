{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import bokeh\n",
    "import geopandas as gpd\n",
    "import scipy\n",
    "import libpysal\n",
    "import momepy\n",
    "import json\n",
    "from dask import delayed\n",
    "import glob\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import momepy\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Point\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "local_crs = 3414\n",
    "\n",
    "place = \"singapore\"\n",
    "\n",
    "latlng = (103.85, 1.29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daskCluster = LocalCluster(threads_per_worker=1,\n",
    "                n_workers=8, memory_limit='100GB')\n",
    "\n",
    "client = Client(daskCluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./out/{place}/what_cells_are_in_what_cluster_dict.json', 'r') as f:\n",
    "#     includes_dict = json.load(f)\n",
    "    \n",
    "tessellation = gpd.read_parquet(f\"./out/{place}/tessellation.pq\")\n",
    "\n",
    "buildings = gpd.read_parquet(f\"./out/{place}/buildings.pq\")\n",
    "\n",
    "streets = gpd.read_parquet(f\"./out/{place}/streets.pq\").explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Map for comparison\n",
    "# f, ax = plt.subplots(figsize=(200, 200))\n",
    "# tessellation.plot(linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "# streets.plot(ax=ax, color='blue')\n",
    "# buildings.plot(ax=ax, color='black', alpha=0.5)\n",
    "# ax.set_axis_off()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation = tessellation[[\"uID\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings[[\"uID\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets['nID'] = momepy.unique_id(streets)\n",
    "streets = streets.reset_index().drop([\"level_0\", \"level_1\"], axis=1)\n",
    "# buildings['nID'] = momepy.get_network_id(buildings, streets,\n",
    "#                                                'nID').values\n",
    "\n",
    "# buildings = buildings.drop_duplicates(\"uID\").drop(columns=\"index_right\")\n",
    "# tessellation = tessellation.merge(buildings[['uID', 'nID']], on='uID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dask.delayed\n",
    "# def queen_contiguity_load(n1, includes_dict):\n",
    "#     chunk = gpd.read_parquet(f\"./out/{place}/expanded_cells_in_chunk_{int(n1)}.pq\")\n",
    "    \n",
    "#     # weights\n",
    "    # queen_1 = libpysal.weights.w_subset(momepy.sw_high(k=1, gdf=chunk, ids='uID'), includes_dict[str(n1)]).to_adjlist()\n",
    "    # queen_3 = libpysal.weights.w_subset(momepy.sw_high(k=3, gdf=chunk, ids='uID'), includes_dict[str(n1)]).to_adjlist()\n",
    "    \n",
    "#     return (queen_1, queen_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_pattern = f\"./out/{place}/expanded_cells_in_chunk_*.pq\"\n",
    "# file_list = glob.glob(file_pattern)\n",
    "# num_files = len(file_list)\n",
    "\n",
    "# weight_out = [process(n1, includes_dict) for n1 in tqdm(range(num_files))]\n",
    "\n",
    "# weight_out = [queen_contiguity_load(n1, includes_dict) for n1 in range(num_files)]\n",
    "\n",
    "# weight_out = dask.compute(weight_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queen_1 = libpysal.weights.W.from_adjlist(pd.concat(weight_out[0][i][0] for i in range(num_files)))\n",
    "\n",
    "# queen_3 = libpysal.weights.W.from_adjlist(pd.concat(weight_out[0][i][1] for i in range(num_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latlng_series = gpd.GeoSeries([Point(latlng)], crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildings[\"building_distance_to_central_city\"] = buildings.geometry.centroid.distance(latlng_series.to_crs(local_crs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the uIDs in tessellation that are not in buildings\n",
    "# tessellation_uids = set(tessellation['uID'])\n",
    "# buildings_uids = set(buildings['uID'])\n",
    "# new_uids = tessellation_uids - buildings_uids\n",
    "\n",
    "# # Create a new GeoDataFrame with the new uIDs and empty geometry\n",
    "# new_rows = pd.DataFrame({'uID': list(new_uids)})\n",
    "# new_rows['geometry'] = None\n",
    "# new_gdf = gpd.GeoDataFrame(new_rows, crs=buildings.crs)\n",
    "\n",
    "# # Append the new GeoDataFrame to buildings\n",
    "# new_buildings = pd.concat([buildings, new_gdf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building Area\n",
    "buildings['building_area'] = momepy.Area(buildings).series\n",
    "tessellation['tess_area'] = momepy.Area(tessellation).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuity = momepy.COINS(streets)\n",
    "# stroke_gdf = continuity.stroke_gdf()\n",
    "\n",
    "streets[\"continuity_stroke\"] = continuity.stroke_attribute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_1 = libpysal.weights.fuzzy_contiguity(tessellation, tolerance=0.05, buffering=True, drop=True, buffer=5, ids=\"uID\", silence_warnings=True)\n",
    "queen_3 = momepy.sw_high(k=3, weights=queen_1)\n",
    "dist200 = libpysal.weights.DistanceBand.from_dataframe(buildings, 200, ids='uID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['building_circular_compactness'] = momepy.CircularCompactness(buildings).series\n",
    "buildings['building_elongation'] = momepy.Elongation(buildings).series\n",
    "buildings['building_squareness'] = momepy.Squareness(buildings).series\n",
    "buildings['building_eri'] = momepy.EquivalentRectangularIndex(buildings).series\n",
    "buildings['building_orientation'] = momepy.Orientation(buildings).series\n",
    "streets['street_linearity'] = momepy.Linearity(streets).series\n",
    "tessellation[\"tess_convexity\"] = momepy.Convexity(tessellation).series\n",
    "tessellation[\"tess_neighbours\"] = momepy.Neighbors(tessellation, queen_3,'uID', weighted=True).series\n",
    "tessellation[\"tess_neighbours_200\"] =  momepy.Neighbors(tessellation, dist200, 'uID', weighted=True).series\n",
    "tessellation[\"tess_covered_area\"] = momepy.CoveredArea(tessellation, queen_1, \"uID\").series\n",
    "tessellation[\"tess_area_iqr\"] = momepy.Range(tessellation, values='tess_area', spatial_weights=queen_3, unique_id='uID', rng=(25, 75)).series\n",
    "tessellation[\"tess_rea_theil\"] = momepy.Theil(tessellation, values='tess_area', spatial_weights=queen_3, unique_id='uID').series\n",
    "tessellation[\"tess_orientation\"] = momepy.Orientation(tessellation).series\n",
    "tessellation[\"building_neighbour_dist\"] = momepy.NeighborDistance(buildings, queen_1, 'uID').series\n",
    "tessellation[\"building_neighbourhood_interbuilding_distance\"] = momepy.MeanInterbuildingDistance(buildings, queen_1, 'uID', 3).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StreetProfile computation\n",
    "profile = momepy.StreetProfile(streets, buildings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets[\"street_width\"] = profile.w\n",
    "streets[\"street_width_deviation\"] = profile.wd\n",
    "streets[\"street_openness\"] = profile.o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['building_weighted_circom'] = momepy.WeightedCharacter(\n",
    "buildings, buildings[\"building_circular_compactness\"], queen_3, 'uID', momepy.Area(buildings).series).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primal = momepy.gdf_to_nx(streets, approach='primal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# momepy.node_degree(primal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# primal = momepy.closeness_centrality(primal, radius=400, name='closeness400', distance='mm_len', weight='mm_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# primal = momepy.meshedness(primal, radius=400, distance=\"mm_len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# primal = momepy.straightness_centrality(primal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# primal = momepy.closeness_centrality(primal, name='closeness_global', weight='mm_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# primal =  momepy.betweenness_centrality(primal, name='betweenness_metric_n', mode='nodes', weight='mm_len', k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# primal = momepy.straightness_centrality(primal)\n",
    "# # momepy.mean_nodes(primal, 'straightness')\n",
    "# momepy.mean_nodes(primal, 'closeness400')\n",
    "# # momepy.mean_nodes(primal, 'closeness_global')\n",
    "# # momepy.mean_nodes(primal, 'betweenness_metric_n')\n",
    "\n",
    "# nodes, streets = momepy.nx_to_gdf(primal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(streets.columns)\n",
    "cols.remove('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_dropped = streets.drop(cols,axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.set_crs(local_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildings=buildings.drop([\"index_right\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = gpd.sjoin_nearest(left_df=buildings, right_df=streets_dropped, how='left', max_distance=1000).drop_duplicates(subset=['geometry'])\n",
    "duplicates = buildings[buildings.duplicated(['uID'], keep=False)]\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"There are {len(duplicates)} rows with duplicate uids.\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"There are no rows with duplicate uids.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.dropna(subset=['geometry'])\n",
    "tessellation = tessellation.dropna(subset=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets[\"nID\"]= streets.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets[\"nID\"]= streets.index\n",
    "buildings =  gpd.sjoin_nearest(buildings, streets, how=\"left\", max_distance=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"building_str_align\"] = momepy.StreetAlignment(buildings, streets,\n",
    "                                   'building_orientation', 'nID',\n",
    "                                   'nID').series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"building_str_align\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blg_cell_align = momepy.CellAlignment(buildings, tessellation,\n",
    "                                      'building_orientation', 'tess_orientation',\n",
    "                                      'uID', 'uID')\n",
    "buildings['building_cell_align'] = blg_cell_align.series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['building_cell_align']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation['tess_car'] = momepy.AreaRatio(tessellation, buildings, 'tess_area', 'building_area', 'uID').series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = gpd.read_parquet(f\"./out/{place}/vertices_frame.pq\")\n",
    "edges = gpd.read_parquet(f\"./out/{place}/edges_frame.pq\")\n",
    "dual = gpd.read_parquet(f\"./out/{place}/dual_vertices_frame.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.drop([\"nID\", \"index_right\", \"nID\"], axis=1)\n",
    "nodes = nodes.drop([\"vertID\"], axis=1)\n",
    "edges = edges.drop(\"edgeID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = gpd.sjoin_nearest(left_df=buildings, right_df=nodes, how='left', max_distance=1000).drop_duplicates(subset=['geometry'])\n",
    "duplicates = buildings[buildings.duplicated(['uID'], keep=False)]\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"There are {len(duplicates)} rows with duplicate uids.\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"There are no rows with duplicate uids.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.drop(\"index_right\", axis=1)\n",
    "buildings = gpd.sjoin_nearest(left_df=buildings, right_df=edges, how='left', max_distance=1000).drop_duplicates(subset=['geometry'])\n",
    "duplicates = buildings[buildings.duplicated(['uID'], keep=False)]\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"There are {len(duplicates)} rows with duplicate uids.\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"There are no rows with duplicate uids.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.drop(\"index_right\", axis=1)\n",
    "buildings = gpd.sjoin_nearest(left_df=buildings, right_df=dual, how='left', max_distance=1000).drop_duplicates(subset=['geometry'])\n",
    "duplicates = buildings[buildings.duplicated(['uID'], keep=False)]\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"There are {len(duplicates)} rows with duplicate uids.\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"There are no rows with duplicate uids.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation = tessellation.merge(buildings, how='left', left_on = \"uID\", right_on=\"uID\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation = tessellation.drop([\"geometry_y\", \"index_right\"], axis=1)\n",
    "tessellation = tessellation.rename(columns={\"geometry_x\": \"geometry\"})\n",
    "tessellation = gpd.GeoDataFrame(tessellation.dropna(subset=['geometry']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./out/{place}/weights.pickle\", 'wb') as f:\n",
    "    pickle.dump(queen_1, f)\n",
    "    pickle.dump(queen_3, f)\n",
    "    pickle.dump(dist200, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.columns=tessellation.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.to_parquet(f\"./out/{place}/tessellation_stats_no_percentile.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataframe(df, num_dfs):\n",
    "#     \"\"\"\n",
    "#     This function splits a DataFrame into a list of smaller DataFrames with equal number of columns.\n",
    "\n",
    "#     Parameters:\n",
    "#     df (pandas.DataFrame): The DataFrame to split.\n",
    "#     num_dfs (int): The number of DataFrames to split 'df' into.\n",
    "\n",
    "#     Returns:\n",
    "#     list: A list of pandas DataFrame objects.\n",
    "#     \"\"\"\n",
    "\n",
    "#     dfs = []\n",
    "#     n = df.shape[1]\n",
    "#     num_cols = n // num_dfs\n",
    "\n",
    "#     for i in range(num_dfs):\n",
    "#         start = i * num_cols\n",
    "#         end = (i + 1) * num_cols if i != num_dfs - 1 else n\n",
    "#         dfs.append(df.iloc[:, start:end])\n",
    "\n",
    "#     return dfs\n",
    "\n",
    "# # Use the function\n",
    "# list_of_dfs = split_dataframe(tessellation[tessellation.columns.drop([\"uID\", \"geometry\"])], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = tessellation.drop([\"uID\", \"geometry\"], axis=1)\n",
    "\n",
    "column_lists = [list(dropped.columns[i:i + 16]) \n",
    "                for i in range(0, len(dropped.columns), 16)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_percentiles(tessellation, queen_3):\n",
    "#     percentiles = []\n",
    "#     for column in tessellation.columns.drop([\"uID\", \"geometry\"]):\n",
    "#         perc = momepy.Percentiles(tessellation, column, queen_3, \"uID\", verbose=False).frame\n",
    "#         perc.columns = [f\"{column}_\" + str(x) for x in perc.columns]\n",
    "#         percentiles.append(perc)\n",
    "        \n",
    "#     percentiles_joined = pd.concat(percentiles, axis=1)\n",
    "#     return percentiles_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_percentiles(df, column, queen_3):\n",
    "    perc = momepy.Percentiles(df, column, queen_3, \"uID\", verbose=False).frame\n",
    "    perc.columns = [f\"{column}_\" + str(x) for x in perc.columns]\n",
    "    \n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_3_future = client.scatter(queen_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofdf = []\n",
    "for column_list in column_lists:\n",
    "    computations = []\n",
    "\n",
    "    for column in column_list:\n",
    "        computations.append(delayed(process_percentiles)(tessellation[['uID', column]], column, queen_3_future))\n",
    "        \n",
    "    out = client.compute(computations)\n",
    "    \n",
    "    \n",
    "    {listofdf.append(out[i].result()) for i in range(len(column_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_joined = pd.concat(listofdf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([percentiles_joined, tessellation[['uID', 'geometry']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_joined[\"uID\"] = tessellation[\"uID\"]\n",
    "percentiles_joined[\"geometry\"] = tessellation[\"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(percentiles_joined, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_parquet(f\"./out/{place}/tessellation_stats.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_size = 250000\n",
    "# chunks = []\n",
    "# for i in range(0, len(tessellation), chunk_size):\n",
    "#     chunks.append(tessellation.iloc[i:i + chunk_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# new_directory = f\"./out/{place}/tessellation/\"\n",
    "\n",
    "# if not os.path.exists(new_directory):\n",
    "#     os.makedirs(new_directory)\n",
    "#     print(f\"Created directory: {new_directory}\")\n",
    "# else:\n",
    "#     print(f\"Directory already exists: {new_directory}\")\n",
    "\n",
    "# # iterate over all files in the directory and delete them\n",
    "# for filename in os.listdir(new_directory):\n",
    "#     file_path = os.path.join(new_directory, filename)\n",
    "#     if os.path.isfile(file_path):\n",
    "#         os.remove(file_path)\n",
    "#         print(f\"Deleted file: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, chunk in enumerate(chunks):\n",
    "#     chunk.to_parquet(f\"./out/{place}/tessellation/tesselation_chunk_{i}.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates = tessellation[tessellation.duplicated(['uID'], keep=False)]\n",
    "# if len(duplicates) > 0:\n",
    "#     print(f\"There are {len(duplicates)} rows with duplicate uids.\")\n",
    "#     print(duplicates)\n",
    "# else:\n",
    "#     print(\"There are no rows with duplicate uids.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Open the file for reading\n",
    "# with open('./out/{place}/weights.pickle', 'rb') as f:\n",
    "#     # Load the variables in the same order that they were dumped\n",
    "#     queen_1 = pickle.load(f)\n",
    "#     queen_3 = pickle.load(f)\n",
    "#     dist200 = pickle.load(f)\n",
    "#     tessellation = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tessellation.to_parquet(\"./out/{place}/tessellation_with_data.pq\", write_metadata_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daskCluster.close()\n",
    "client.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
